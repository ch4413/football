{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "\n",
    "from empiricaldist import Pmf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from results.csv\n",
    "results = pd.read_csv('../data/results.csv')\n",
    "teams = pd.read_csv('../data/teams.csv')\n",
    "fixtures = pd.read_csv('../data/fixtures.csv')\n",
    "# Define the outcome variable\n",
    "results['Outcome'] = results.apply(\n",
    "    lambda row: 'HomeWin' if row['HomeScore'] > row['AwayScore'] \n",
    "    else ('Draw' if row['HomeScore'] == row['AwayScore'] else 'AwayWin'), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_points(a, b):\n",
    "    \"\"\" Win, lose, draw 3, 0, 1 \"\"\"\n",
    "    if a > b:\n",
    "        return [3, 0]\n",
    "    if b > a:\n",
    "        return [0, 3]\n",
    "    if b == a:\n",
    "        return [1, 1]\n",
    "    else:\n",
    "        return ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_by_week(df):\n",
    "    new_df = df.copy()\n",
    "    home = new_df[['Gameweek', 'HomeTeamID', 'HomePoints', 'HomeScore', 'AwayScore']].copy()\n",
    "    away = new_df[['Gameweek', 'AwayTeamID', 'AwayPoints', 'AwayScore', 'HomeScore']].copy()\n",
    "    cols = ['Gameweek', 'ID', 'Points', 'For', 'Against']\n",
    "    home.columns = cols\n",
    "    away.columns = cols\n",
    "    points_by_week = pd.concat([home, away])\n",
    "    return points_by_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fixture - get fixture\n",
    "fixture_predict = fixtures[fixtures.index==0]\n",
    "def get_goals_data(selected_fixture, results_data):\n",
    "    \"\"\"Given a fixture row from the data\n",
    "    filter the data to return the head to head records for\n",
    "    the teams and then give vectors for their goal scoring\n",
    "    # TODO: (1) remove head to from all fixtures - remove double count\n",
    "    (2) Treats home and away as the same - needs to factor this in - create separate model?\n",
    "    (3) Doesn't use the data for shots taken - can be added into score as XG\n",
    "    (4) Doesn't account for goals conceded - !! need to look up\n",
    "    \"\"\"\n",
    "    # Assign team A home, and team B away \n",
    "    teams_ab = [selected_fixture['HomeTeamID'].values[0], selected_fixture['AwayTeamID'].values[0]]\n",
    "    # Get matches for each scores for teams against each other\n",
    "    head2head = results_data[results_data['HomeTeamID'].isin(teams_ab) & \n",
    "                             results_data['AwayTeamID'].isin(teams_ab)]\n",
    "    # create team 1 and team 2 list of goals\n",
    "    team_a_scores = [head2head[head2head['HomeTeamID']==teams_ab[0]]['HomeScore'].values[0],\n",
    "                     head2head[head2head['AwayTeamID']==teams_ab[0]]['AwayScore'].values[0]]\n",
    "    team_b_scores = [head2head[head2head['AwayTeamID']==teams_ab[1]]['AwayScore'].values[0],\n",
    "                     head2head[head2head['HomeTeamID']==teams_ab[1]]['HomeScore'].values[0]]\n",
    "    # get all goals for teams\n",
    "    team_a_goals = pd.concat([results_data[results_data['HomeTeamID']==teams_ab[0]]['HomeScore'],\n",
    "                              results_data[results_data['AwayTeamID']==teams_ab[0]]['AwayScore']])\n",
    "    team_b_goals = pd.concat([results_data[results_data['AwayTeamID']==teams_ab[1]]['AwayScore'],\n",
    "                              results_data[results_data['HomeTeamID']==teams_ab[1]]['HomeScore']])\n",
    "    \n",
    "    return {'teams': teams_ab, 'head2head': [team_a_scores, team_b_scores], 'team_goals': [team_a_goals, team_b_goals]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_beta(teams_data):\n",
    "    \"\"\"Take in Teams data and create alpha, beta\n",
    "    for gamma dist team A, team B\n",
    "    TODO: (1)check formula for calculating alpha, beta,\n",
    "    (2) Check what data should go into alpha, beta for goals\n",
    "    Is the distribution of goals scored before a good measure?\n",
    "    \"\"\"\n",
    "    team_goals = teams_data['team_goals']\n",
    "    alpha_a = team_goals[0].mean()**2 / team_goals[0].var()\n",
    "    beta_a = team_goals[0].var() / team_goals[0].mean()\n",
    "\n",
    "    alpha_b = team_goals[1].mean()**2 / team_goals[1].var()\n",
    "    beta_b = team_goals[1].var() / team_goals[1].mean()\n",
    "\n",
    "    return [[alpha_a, beta_a], [alpha_b, beta_b]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single prediction for ID 2 Vs. 1\n",
    "def fit_gp_model(teams_data, alpha_beta):\n",
    "    \"\"\" Initialise model, fit priors w/ alpha, beta\n",
    "    update with observed results\n",
    "    \"\"\"\n",
    "    model = pm.Model()\n",
    "    with model:\n",
    "        mu_a = pm.Gamma('mu_a', alpha_beta[0][0], alpha_beta[0][1])\n",
    "        mu_b = pm.Gamma('mu_b', alpha_beta[1][0], alpha_beta[1][1])\n",
    "        goals_1 = pm.Poisson('goals_a', mu_a, observed=teams_data['head2head'][0])\n",
    "        goals_2 = pm.Poisson('goals_b', mu_b, observed=teams_data['head2head'][1])\n",
    "        trace = pm.sample(300)\n",
    "    return model, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_results(model, trace):\n",
    "    \"\"\"\n",
    "    Sample posterior for predictions and return 1000 runs of\n",
    "    goals for team A and team B\n",
    "    TODO: Why do I get 2000 results from 1000 samples?\n",
    "    \"\"\"\n",
    "    with model:\n",
    "        post_pred = pm.sample_posterior_predictive(trace, samples=300)\n",
    "    goals_a = post_pred['goals_a'].flatten()\n",
    "    goals_b = post_pred['goals_b'].flatten()\n",
    "    return [goals_a, goals_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(teams_data, match_results):\n",
    "    \"\"\"Calculate the result probabilities for\n",
    "    win, lose, draw for the fixture and format\n",
    "    with the teams data\n",
    "    TODO: sort out what is the right output format\n",
    "    \"\"\"\n",
    "    win = np.mean(match_results[0] > match_results[1])\n",
    "    lose = np.mean(match_results[0] < match_results[1])\n",
    "    draw = np.mean(match_results[0] == match_results[1])\n",
    "    result = {'HomeTeamID': [teams_data['teams'][0]],\n",
    "                           'AwayTeamID': [teams_data['teams'][1]],\n",
    "                           'HomeWin': [win],\n",
    "                           'AwayWin': [lose],\n",
    "                           'Draw': [draw]\n",
    "                           }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get data\n",
    "def run_pipeline(fixtures, results, index):\n",
    "    \"\"\"Run pipeline for fixture index\"\"\"\n",
    "    selected_fix = fixtures[fixtures.index==index]\n",
    "    season1 = results[results['SeasonID']==1]\n",
    "    teams_data = get_goals_data(selected_fix, season1)\n",
    "    alpha_beta = get_alpha_beta(teams_data)\n",
    "    model, trace = fit_gp_model(teams_data, alpha_beta)\n",
    "    match_results = predict_results(model, trace)\n",
    "    results_df = get_probabilities(teams_data, match_results)\n",
    "    print(f'Completed predictions for: {index}')\n",
    "    return results_df, match_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName</th>\n",
       "      <th>Gameweek</th>\n",
       "      <th>Points</th>\n",
       "      <th>For</th>\n",
       "      <th>Against</th>\n",
       "      <th>GD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miami</td>\n",
       "      <td>54</td>\n",
       "      <td>138</td>\n",
       "      <td>159</td>\n",
       "      <td>41</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>54</td>\n",
       "      <td>125</td>\n",
       "      <td>130</td>\n",
       "      <td>51</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baltimore</td>\n",
       "      <td>54</td>\n",
       "      <td>117</td>\n",
       "      <td>136</td>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York S</td>\n",
       "      <td>54</td>\n",
       "      <td>113</td>\n",
       "      <td>108</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston</td>\n",
       "      <td>54</td>\n",
       "      <td>106</td>\n",
       "      <td>130</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TeamName  Gameweek  Points  For  Against   GD\n",
       "0       Miami        54     138  159       41  118\n",
       "1  Cincinnati        54     125  130       51   79\n",
       "2   Baltimore        54     117  136       41   95\n",
       "3  New York S        54     113  108       52   56\n",
       "4      Boston        54     106  130       58   72"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Points'] = results.apply(lambda row: results_points(row['HomeScore'], row['AwayScore']), axis=1)\n",
    "results[['HomePoints', 'AwayPoints']] = pd.DataFrame(results['Points'].tolist(), index=results.index)\n",
    "season1 = results[results['SeasonID']==1]\n",
    "points_by_week_s1 = get_points_by_week(season1)\n",
    "# Sum points over all weeks by Team\n",
    "final_table_s1 = (points_by_week_s1.groupby(['ID']).agg({'Points': 'sum', 'For': 'sum', 'Against': 'sum',\n",
    "                                                         'Gameweek': 'count'})\n",
    "               .reset_index()\n",
    "               .sort_values('Points', ascending=False)\n",
    "               )\n",
    "final_table_s1['GD'] = final_table_s1['For'] - final_table_s1['Against']\n",
    "final_table_s1 = final_table_s1.reset_index().drop('index', axis=1)\n",
    "\n",
    "final_table_s1 = pd.merge(final_table_s1, teams, left_on='ID', right_on='TeamID')\n",
    "final_table_s1[['TeamName', 'Gameweek','Points', 'For', 'Against', 'GD']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_dict = [run_pipeline(fixtures, results, i) for i in range(fixtures.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = results[['Gameweek', 'HomeTeamID', 'HomeScore']]\n",
    "home.columns = ['Gameweek', 'TeamID', 'Score']\n",
    "away = results[['Gameweek', 'AwayTeamID', 'AwayScore']]\n",
    "away.columns = ['Gameweek', 'TeamID', 'Score']\n",
    "goals_df = pd.concat([home, away])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamids = sorted(goals_df['TeamID'].drop_duplicates().to_list())\n",
    "past_goals = {str(x): goals_df[goals_df['TeamID']==x]['Score'].to_list() for x in teamids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_12368\\1071094365.py:13: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(500)#, nuts_kwargs=dict(target_accept=0.95))\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu_28, mu_27, mu_26, mu_25, mu_24, mu_23, mu_22, mu_21, mu_20, mu_19, mu_18, mu_17, mu_16, mu_15, mu_14, mu_13, mu_12, mu_11, mu_10, mu_9, mu_8, mu_7, mu_6, mu_5, mu_4, mu_3, mu_2, mu_1, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 00:22<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 47 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = pm.Model()\n",
    "\n",
    "with model:\n",
    "    alpha = pm.Exponential('alpha', lam=1)\n",
    "    beta = pm.Exponential('beta', lam=1)\n",
    "    \n",
    "    mu = dict()\n",
    "    goals = dict()\n",
    "    for name, observed in past_goals.items():\n",
    "        mu[name] = pm.Gamma('mu_'+ str(name), alpha, beta)\n",
    "        goals[name] = pm.Poisson(name, mu[name], observed=observed)\n",
    "        \n",
    "    trace = pm.sample(500)#, nuts_kwargs=dict(target_accept=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 01:36<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with model:\n",
    "    post_pred = pm.sample_posterior_predictive(trace, samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_1 = post_pred['1'].flatten()\n",
    "goals_2 = post_pred['2'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = np.mean(goals_1 > goals_2)\n",
    "lose = np.mean(goals_1 < goals_2)\n",
    "draw = np.mean(goals_1 == goals_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5096379629629629, 0.2404388888888889, 0.24992314814814814)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win, lose, draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
