{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_points(a, b):\n",
    "    \"\"\" Win, lose, draw 3, 0, 1 \"\"\"\n",
    "    if a > b:\n",
    "        return [3, 0]\n",
    "    if b > a:\n",
    "        return [0, 3]\n",
    "    if b == a:\n",
    "        return [1, 1]\n",
    "    else:\n",
    "        return ValueError\n",
    "    \n",
    "def prob_result(hw, aw, d):\n",
    "    \n",
    "    value = np.argmax(np.array([hw, aw, d])\n",
    "                                )\n",
    "    if value == 0:\n",
    "        return 'HomeWin'\n",
    "    if value == 1:\n",
    "        return 'AwayWin'\n",
    "    if value == 2:\n",
    "        return 'Draw'\n",
    "    else:\n",
    "        return ValueError\n",
    "    \n",
    "def get_points_by_week(df):\n",
    "    new_df = df.copy()\n",
    "    home = new_df[['Gameweek', 'HomeTeamID', 'HomePoints', 'HomeScore', 'AwayScore']].copy()\n",
    "    away = new_df[['Gameweek', 'AwayTeamID', 'AwayPoints', 'AwayScore', 'HomeScore']].copy()\n",
    "    cols = ['Gameweek', 'ID', 'Points', 'For', 'Against']\n",
    "    home.columns = cols\n",
    "    away.columns = cols\n",
    "    points_by_week = pd.concat([home, away])\n",
    "    return points_by_week\n",
    "\n",
    "def predict_match(homeid, awayid, gameweek, results_df):\n",
    "    \"\"\" Take Home and Away IDs for a fixture and\n",
    "    predict the result from the means of the simulated goals.\n",
    "    Assign W, L, D and return dict\n",
    "    \"\"\"\n",
    "    goals_1 = results_df[homeid]\n",
    "    goals_2 = results_df[awayid]\n",
    "\n",
    "    win = np.mean(goals_1 > goals_2)\n",
    "    lose = np.mean(goals_1 < goals_2)\n",
    "    draw = np.mean(goals_1 == goals_2)\n",
    "\n",
    "    results = {'Gameweek': gameweek,'HomeTeamID': homeid, 'AwayTeamID': awayid,\n",
    "               'HomeWin': win, 'AwayWin': lose, 'Draw': draw}\n",
    "    return results\n",
    "\n",
    "def create_sim_season(fixtures, sim_results, i):\n",
    "    \"\"\"Combine the base fixtures with a set of simulation\n",
    "    results for goals scored. Get points per team by week using\n",
    "     results_points, get_points_by_week\n",
    "     \"\"\"\n",
    "    sim_fixtures = fixtures[['Gameweek', 'HomeTeamID', 'AwayTeamID']].copy()\n",
    "    sim_fixtures['HomeScore'] = sim_results[:, 0, i]\n",
    "    sim_fixtures['AwayScore'] = sim_results[:, 1, i]\n",
    "    sim_fixtures['Points'] = sim_fixtures.apply(lambda row: results_points(row['HomeScore'], row['AwayScore']), axis=1)\n",
    "    sim_fixtures[['HomePoints', 'AwayPoints']] = pd.DataFrame(sim_fixtures['Points'].tolist(), index=sim_fixtures.index)\n",
    "\n",
    "    return get_points_by_week(sim_fixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from results.csv\n",
    "results = pd.read_csv('../data/results.csv')\n",
    "teams = pd.read_csv('../data/teams.csv')\n",
    "fixtures = pd.read_csv('../data/fixtures.csv')\n",
    "# Define the outcome variable\n",
    "results['Outcome'] = results.apply(\n",
    "    lambda row: 'HomeWin' if row['HomeScore'] > row['AwayScore'] \n",
    "    else ('Draw' if row['HomeScore'] == row['AwayScore'] else 'AwayWin'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = results[['Gameweek', 'HomeTeamID', 'HomeScore']]\n",
    "home.columns = ['Gameweek', 'TeamID', 'Score']\n",
    "away = results[['Gameweek', 'AwayTeamID', 'AwayScore']]\n",
    "away.columns = ['Gameweek', 'TeamID', 'Score']\n",
    "goals_df = pd.concat([home, away])\n",
    "\n",
    "teamids = sorted(goals_df['TeamID'].drop_duplicates().to_list())\n",
    "past_goals = {str(x): goals_df[goals_df['TeamID']==x]['Score'].to_list() for x in teamids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_25172\\1071094365.py:13: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(500)#, nuts_kwargs=dict(target_accept=0.95))\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu_28, mu_27, mu_26, mu_25, mu_24, mu_23, mu_22, mu_21, mu_20, mu_19, mu_18, mu_17, mu_16, mu_15, mu_14, mu_13, mu_12, mu_11, mu_10, mu_9, mu_8, mu_7, mu_6, mu_5, mu_4, mu_3, mu_2, mu_1, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6000' class='' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6000/6000 00:24<00:00 Sampling 4 chains, 6 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 52 seconds.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "model = pm.Model()\n",
    "\n",
    "with model:\n",
    "    alpha = pm.Exponential('alpha', lam=1)\n",
    "    beta = pm.Exponential('beta', lam=1)\n",
    "    \n",
    "    mu = dict()\n",
    "    goals = dict()\n",
    "    for name, observed in past_goals.items():\n",
    "        mu[name] = pm.Gamma('mu_'+ str(name), alpha, beta)\n",
    "        goals[name] = pm.Poisson(name, mu[name], observed=observed)\n",
    "        \n",
    "    trace = pm.sample(500)#, nuts_kwargs=dict(target_accept=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 01:37<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with model:\n",
    "    post_pred = pm.sample_posterior_predictive(trace, samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of results\n",
    "results_df = pd.DataFrame({x : post_pred[x].flatten() for x in post_pred.keys()})\n",
    "# Get HomeID, Away ID\n",
    "homeid = fixtures['HomeTeamID'].to_list()\n",
    "awayid = fixtures['AwayTeamID'].to_list()\n",
    "gameweek = fixtures['Gameweek'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results from all seasons, filter for season 2\n",
    "season2 = results[results['SeasonID']==2]\n",
    "results_df_m = pd.DataFrame([predict_match(str(homeid[i]),\n",
    "                                           str(awayid[i]),\n",
    "                                           gameweek[i],\n",
    "                                           results_df) for i in range(len(homeid))])\n",
    "results_df_m['HomeTeamID'] = results_df_m['HomeTeamID'].astype('int')\n",
    "results_df_m['AwayTeamID'] = results_df_m['AwayTeamID'].astype('int')\n",
    "\n",
    "results_df_m['Prob_outcome'] = results_df_m.apply(lambda row: prob_result(row['HomeWin'], row['AwayWin'],\n",
    "                                                             row['Draw']), axis=1)\n",
    "season2_outcome = season2['Outcome'].reset_index()\n",
    "results_df_m['Outcome'] = season2_outcome['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6084656084656085"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results_df_m['Prob_outcome']==results_df_m['Outcome']).sum() / results_df_m.shape[0]\n",
    "# to add: precision, recall, f1 score, confusion matrix, Cohen's kappa?, log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict season outcome x1000 - done, nice work\n",
    "homeids = fixtures['HomeTeamID'].to_list()\n",
    "awayids = fixtures['AwayTeamID'].to_list()\n",
    "sim_results = np.zeros([756, 2, 1000])\n",
    "for i in range(fixtures.shape[0]):\n",
    "    homeid = str(homeids[i])\n",
    "    awayid = str(awayids[i])\n",
    "    homescore = results_df[homeid].sample(1000).values\n",
    "    awayscore = results_df[awayid].sample(1000).values\n",
    "    sim_results[i, 0, :] = homescore\n",
    "    sim_results[i, 1, :] = awayscore\n",
    "    \n",
    "table_finishes = {x : [] for x in fixtures['HomeTeamID'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_finishes = {x : [] for x in fixtures['HomeTeamID'].unique()}\n",
    "for x in range(1000):\n",
    "    points_by_week_sim = create_sim_season(fixtures, sim_results, x)\n",
    "    final_table_sim = (points_by_week_sim.groupby(['ID']).agg({'Points': 'sum', 'For': 'sum', 'Against': 'sum'})\n",
    "                .reset_index()\n",
    "                .sort_values('Points', ascending=False)\n",
    "                )\n",
    "    final_table_sim = final_table_sim.reset_index(drop=True)\n",
    "    [table_finishes[final_table_sim['ID'][i]].append(i+1) for i in range(final_table_sim.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(table_finishes[15]).values_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
