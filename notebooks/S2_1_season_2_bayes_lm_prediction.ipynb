{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom package\n",
    "import footballanalysis.model.bayes as fmb\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymc3 as pm\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../data/results.csv')\n",
    "results['Outcome'] = results.apply(\n",
    "    lambda row: 'HomeWin' if row['HomeScore'] > row['AwayScore'] \n",
    "    else ('Draw' if row['HomeScore'] == row['AwayScore'] else 'AwayWin'), axis=1)\n",
    "season1 = results[results['SeasonID']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_teams = season1['HomeTeamID'].nunique()\n",
    "\n",
    "home_ad_results = season1[['HomeTeamID', 'AwayTeamID', 'HomeScore']].copy()\n",
    "home_ad_results.columns = ['Team', 'Opponent', 'goals']\n",
    "home_ad_results['Home_ad'] = 1\n",
    "away_ad_results = season1[['AwayTeamID', 'HomeTeamID', 'AwayScore']].copy()\n",
    "away_ad_results.columns = ['Team', 'Opponent', 'goals']\n",
    "away_ad_results['Home_ad'] = 0\n",
    "all_ad_results = pd.concat([home_ad_results, away_ad_results])\n",
    "all_ad_results['Team'] -= 1\n",
    "all_ad_results['Opponent'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, home_adv_effect, opponent_effect, team_effect]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='44000' class='' max='44000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [44000/44000 05:20<00:00 Sampling 4 chains, 3 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 10_000 draw iterations (4_000 + 40_000 draws total) took 344 seconds.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# Create LM for expected goals, w/ team, opponent, home\n",
    "with pm.Model() as model:\n",
    "    # Priors: team, opponent, home, error\n",
    "    team_effect = pm.Normal(\"team_effect\", mu=0, sigma=1, shape=num_teams)\n",
    "    opponent_effect = pm.Normal(\"opponent_effect\", mu=0, sigma=1, shape=num_teams)\n",
    "    home_adv_effect = pm.Normal(\"home_adv_effect\", mu=0, sigma=1)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "    \n",
    "    # data\n",
    "    teams = all_ad_results['Team'].to_list()\n",
    "    opponents = all_ad_results['Opponent'].to_list()\n",
    "    home_advantage = all_ad_results['Home_ad'].to_list()\n",
    "    goals = all_ad_results['goals'].to_list()\n",
    "    # model\n",
    "    mu = (team_effect[teams] - opponent_effect[opponents] + home_adv_effect * home_advantage)\n",
    "    \n",
    "    # y-values\n",
    "    y_obs = pm.Poisson(\"y_obs\", mu=np.exp(mu), observed=goals)\n",
    "    trace = pm.sample(10000, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use model to predict outcomes and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HomeID, Away ID\n",
    "fixtures = pd.read_csv('../data/fixtures.csv')\n",
    "homeids = fixtures['HomeTeamID'].to_list()\n",
    "awayids = fixtures['AwayTeamID'].to_list()\n",
    "gameweeks = fixtures['Gameweek'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_probs = pd.DataFrame([\n",
    "    fmb.get_probs(homeids[i], awayids[i], gameweeks[i], trace) for i in range(fixtures.shape[0])\n",
    "    ])\n",
    "    \n",
    "match_probs['Prob_outcome'] = match_probs.apply(lambda row: fmb.prob_result(row['HomeWinPred'], row['AwayWinPred'],\n",
    "                                                             row['DrawPred']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test: Compare to true outcome (accuracy), odds vs outcome (log loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "season2 = results[results['SeasonID']==2].copy()\n",
    "season2['Outcome_encoded'] = season2['Outcome'].map({'HomeWin': 0, 'AwayWin': 1, 'Draw': 2})\n",
    "season2_outcome = season2[['Outcome', 'Outcome_encoded']].reset_index()\n",
    "match_probs[['Outcome', 'Outcome_encoded']] = season2_outcome[['Outcome', 'Outcome_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy\n",
    "lm_accuracy = (match_probs['Prob_outcome']==match_probs['Outcome']).sum() / match_probs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log-loss of new pred Vs. odds\n",
    "log_loss_lm = log_loss(match_probs['Outcome_encoded'].values, match_probs[['HomeWinPred', 'AwayWinPred', 'DrawPred']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = pd.read_csv('../data/odds.csv')\n",
    "odds[['Home', 'Draw', 'Away']] = 1 / odds[['Home', 'Draw', 'Away']]\n",
    "results_odds = results.merge(odds, on='MatchID')\n",
    "season2_ro = results_odds[results_odds['SeasonID']==2]\n",
    "season2_ro = season2_ro.reset_index(drop=True)\n",
    "season2_ro['Outcome_encoded'] = season2_ro['Outcome'].map({'HomeWin': 0, 'AwayWin': 1, 'Draw': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "season2_ro['Prob_outcome_odds'] = season2_ro.apply(lambda row: fmb.prob_result(row['Home'], row['Away'],\n",
    "                                                             row['Draw']), axis=1)\n",
    "### Accuracy\n",
    "odds_accuracy = (season2_ro['Prob_outcome_odds']==season2_ro['Outcome']).sum() / season2_ro.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise odds: didn't add to 1 when inverted\n",
    "season2_ro['norm_factor'] = season2_ro[['Home', 'Away', 'Draw']].sum(axis=1)\n",
    "season2_ro[['Home_n', 'Away_n', 'Draw_n']] = season2_ro[['Home', 'Away', 'Draw']].div(season2_ro['norm_factor'], axis=0)\n",
    "\n",
    "log_loss_odds = log_loss(season2_ro['Outcome_encoded'].values, season2_ro[['Home_n', 'Away_n', 'Draw_n']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6124338624338624, 0.6309523809523809)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_accuracy, odds_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8735667797459136, 0.8623406373108837)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_lm, log_loss_odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table Finishes Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict season outcome x1000 - done, nice work\n",
    "homeids = fixtures['HomeTeamID'].to_list()\n",
    "awayids = fixtures['AwayTeamID'].to_list()\n",
    "sim_results = np.zeros([756, 2, 1000])\n",
    "for i in range(fixtures.shape[0]):\n",
    "    homeid = homeids[i]\n",
    "    awayid = awayids[i]\n",
    "    h, a = fmb.get_match_predictions(homeid, awayid, trace)\n",
    "    homescore = pd.Series(h).sample(1000).values\n",
    "    awayscore = pd.Series(a).sample(1000).values\n",
    "    sim_results[i, 0, :] = homescore\n",
    "    sim_results[i, 1, :] = awayscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_finishes = {x : [] for x in fixtures['HomeTeamID'].unique()}\n",
    "for x in range(1000):\n",
    "    points_by_week_sim = fmb.create_sim_season(fixtures, sim_results, x)\n",
    "    final_table_sim = (points_by_week_sim.groupby(['ID']).agg({'Points': 'sum', 'For': 'sum', 'Against': 'sum'})\n",
    "                .reset_index()\n",
    "                .sort_values('Points', ascending=False)\n",
    "                )\n",
    "    final_table_sim = final_table_sim.reset_index(drop=True)\n",
    "    [table_finishes[final_table_sim['ID'][i]].append(i+1) for i in range(final_table_sim.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('table_finishes_lm.pkl', 'wb') as file:\n",
    "    pickle.dump(table_finishes, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
